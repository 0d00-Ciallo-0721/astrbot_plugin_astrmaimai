### ğŸ“„ utils/db_migrate.py
import json
import time
import aiosqlite
import asyncio
from pathlib import Path
from astrbot.api import logger

async def migrate_legacy_data(persistence) -> str:
    """
    æ‰§è¡Œæ—§ç‰ˆ JSON æ•°æ®åˆ° SQLite çš„è¿ç§»
    :param persistence: PersistenceManager å®ä¾‹ (ç”¨äºè·å–è·¯å¾„)
    :return: è¿ç§»ç»“æœæŠ¥å‘Šæ–‡æœ¬
    """
    data_dir = persistence.data_dir
    db_path = persistence.db_path
    
    json_states_path = data_dir / "heartflow_states.json"
    json_profiles_path = data_dir / "heartflow_user_profiles.json"
    
    report = []
    
    # --- 1. è¿ç§»ç¾¤èŠçŠ¶æ€ ---
    if json_states_path.exists():
        try:
            # ä½¿ç”¨ to_thread é˜²æ­¢å¤§æ–‡ä»¶è¯»å–é˜»å¡ Event Loop
            def _read_states():
                with open(json_states_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            
            data = await asyncio.to_thread(_read_states)
            count = 0
            
            async with aiosqlite.connect(db_path) as db:
                for chat_id, state in data.items():
                    # æå–å­—æ®µ (ä¸ datamodels.py ä¿æŒä¸€è‡´)
                    energy = state.get("energy", 0.5)
                    mood = state.get("mood", 0.0)
                    group_config = json.dumps(state.get("group_config", {}), ensure_ascii=False)
                    last_reset_date = state.get("last_reset_date", "")
                    updated_at = time.time()

                    await db.execute("""
                        INSERT OR REPLACE INTO chat_states 
                        (chat_id, energy, mood, group_config, last_reset_date, updated_at)
                        VALUES (?, ?, ?, ?, ?, ?)
                    """, (chat_id, energy, mood, group_config, last_reset_date, updated_at))
                    count += 1
                await db.commit()
            report.append(f"âœ… ç¾¤èŠçŠ¶æ€è¿ç§»æˆåŠŸ: {count} æ¡")
        except Exception as e:
            logger.error(f"Migrate ChatStates Error: {e}")
            report.append(f"âŒ ç¾¤èŠçŠ¶æ€è¿ç§»å¤±è´¥: {e}")
    else:
        report.append("âš ï¸ æœªæ‰¾åˆ°æ—§ç‰ˆç¾¤èŠæ•°æ® (heartflow_states.json)ï¼Œè·³è¿‡ã€‚")

    # --- 2. è¿ç§»ç”¨æˆ·ç”»åƒ ---
    if json_profiles_path.exists():
        try:
            def _read_profiles():
                with open(json_profiles_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            
            data = await asyncio.to_thread(_read_profiles)
            count = 0
            
            async with aiosqlite.connect(db_path) as db:
                for user_id, profile in data.items():
                    # æå–å­—æ®µ
                    name = profile.get("name", "æœªçŸ¥ç”¨æˆ·")
                    social_score = profile.get("social_score", 0.0)
                    last_seen = profile.get("last_seen", 0.0)
                    persona_analysis = profile.get("persona_analysis", "")
                    group_footprints = json.dumps(profile.get("group_footprints", {}), ensure_ascii=False)
                    updated_at = time.time()
                    
                    # [v4.14 ä¿®æ­£] è¿ç§»æ—§æ•°æ®æ—¶ï¼Œlast_persona_gen_time é»˜è®¤ä¸º 0.0
                    last_persona_gen_time = 0.0

                    await db.execute("""
                        INSERT OR REPLACE INTO user_profiles 
                        (user_id, name, social_score, last_seen, persona_analysis, group_footprints, updated_at, last_persona_gen_time)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                    """, (user_id, name, social_score, last_seen, persona_analysis, group_footprints, updated_at, last_persona_gen_time))
                    count += 1
                await db.commit()
            report.append(f"âœ… ç”¨æˆ·ç”»åƒè¿ç§»æˆåŠŸ: {count} æ¡")
        except Exception as e:
            logger.error(f"Migrate UserProfiles Error: {e}")
            report.append(f"âŒ ç”¨æˆ·ç”»åƒè¿ç§»å¤±è´¥: {e}")
    else:
        report.append("âš ï¸ æœªæ‰¾åˆ°æ—§ç‰ˆç”¨æˆ·æ•°æ® (heartflow_user_profiles.json)ï¼Œè·³è¿‡ã€‚")

    return "\n".join(report)